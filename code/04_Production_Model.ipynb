{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c0f8158",
   "metadata": {},
   "source": [
    "# Ames Housing Sale Predictions - Production Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c791f6",
   "metadata": {},
   "source": [
    "## Contents:\n",
    "- [Imports & Data](#Imports-\\&-Data)\n",
    "- [Define X & y](#Define-X-\\&-y)\n",
    "- [Scale Model](#Scale-Model)\n",
    "- [Fit and Asses Model](#Fit-and-Asses-Model)\n",
    "    - [Linear Regression (OLS)](#Linear-Regression-(OLS))\n",
    "    - [Ridge Model](#Ridge-Model)\n",
    "    - [LASSO Model](#LASSO-Model)\n",
    "- [Predictions & Review](#Predictions-\\&-Review)\n",
    "- [Save Submission Data](#Save-Submission-Data)\n",
    "- [Conclusions & Recommendations](#Conclusions-\\&-Recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6807cb8",
   "metadata": {},
   "source": [
    "## Imports & Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f356f1ed",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7703e777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45ea2c1",
   "metadata": {},
   "source": [
    "#### Read In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fd67911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths\n",
    "path_production_data = '../datasets/03_production/'\n",
    "path_submission_data = '../datasets/04_submission/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22c9f137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "df_train = pd.read_csv(f'{path_production_data}train_production.csv')\n",
    "df_test = pd.read_csv(f'{path_production_data}test_production.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2776dec",
   "metadata": {},
   "source": [
    "## Define X & y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9669ad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X & y\n",
    "X_train = df_train.drop(columns='SalePrice')\n",
    "y_train = df_train['SalePrice']\n",
    "\n",
    "# Test Data - for predictions\n",
    "X_test = df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af814210",
   "metadata": {},
   "source": [
    "## Scale Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0dfa215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale model\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6ff048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_train = sc.fit_transform(X_train)\n",
    "Z_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45f140f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mean sum: -0.0\n",
      "Test mean sum: -1.078\n"
     ]
    }
   ],
   "source": [
    "# Review scaled means\n",
    "print(f'Train mean sum: {Z_train.mean(axis=0).sum().round(4)}')\n",
    "print(f'Test mean sum: {Z_test.mean(axis=0).sum().round(4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0206ca3f",
   "metadata": {},
   "source": [
    "## Fit and Asses Model\n",
    "- Only one model is uncommented at a time.\n",
    "- This allows for easy sqitching between models to produce different outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701a6ee7",
   "metadata": {},
   "source": [
    "### Linear Regression (OLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69cb8729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate Model\n",
    "# model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f610125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit model\n",
    "# model.fit(Z_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6346d61",
   "metadata": {},
   "source": [
    "### Ridge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46b76f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a list of ridge alphas to test\n",
    "# r_alphas = np.logspace(0, 1, 500)\n",
    "\n",
    "# # Cross-validate over our list of ridge alphas.\n",
    "# model = RidgeCV(alphas=r_alphas, scoring='r2', cv=10) # Uses MSE by default\n",
    "\n",
    "# # Fit model using best ridge alpha!\n",
    "# model.fit(Z_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f07cda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optimal value of alpha\n",
    "# model.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e944b8e8",
   "metadata": {},
   "source": [
    "### LASSO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a0a3375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of LASSO alphas to test\n",
    "l_alphas = np.logspace(1, 2, 500)\n",
    "\n",
    "# Cross-validate over our list of Lasso alphas.\n",
    "model = LassoCV(alphas=l_alphas, cv=10, max_iter=5000)\n",
    "\n",
    "# Fit model using best lasso alpha!\n",
    "model.fit(Z_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a444bc2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.38913057338779"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimal value of alpha\n",
    "model.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413e1867",
   "metadata": {},
   "source": [
    "## Predictions & Review\n",
    "- Make predictions and review R$^2$\n",
    "- Format data for submission\n",
    "- Final data check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8de81e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_preds = model.predict(Z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abd52624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to df_test\n",
    "df_test['SalePrice'] = y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aec7bd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>147300.722060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2718</th>\n",
       "      <td>158758.907182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2414</th>\n",
       "      <td>211361.910297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>99272.602747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>175110.811257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SalePrice\n",
       "Id                 \n",
       "2658  147300.722060\n",
       "2718  158758.907182\n",
       "2414  211361.910297\n",
       "1989   99272.602747\n",
       "625   175110.811257"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create submission df (correct 'Id' column name and set 'Id' as index)\n",
    "df_submission = df_test[['Id', 'SalePrice']].set_index('Id')\n",
    "print(df_submission.shape) # Confirm this is (878, 1)!\n",
    "df_submission.head() # Id starts with (2658, 2718, 2414, 1989, 625, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "096d31ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R2: 0.9465720446283913\n"
     ]
    }
   ],
   "source": [
    "# Verify Train data R2\n",
    "print(f'Training R2: {model.score(Z_train, y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3f6cba",
   "metadata": {},
   "source": [
    "## Save Submission Data\n",
    "- Save formatted csv for Kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa01346c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission\n",
    "descriptor = 'dum_ord_poly_eng_lasso_5' # describe filename\n",
    "df_submission.to_csv(f'{path_submission_data}cl_submission_{descriptor}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82878701",
   "metadata": {},
   "source": [
    "## Conclusions & Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96c15fa",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Our team of data scientists analyzed the Ames, IA housing dataset to determine if the data provided meaningful information about the Sale Price of each home.\n",
    "\n",
    "We initially cleaned the data to account for abnormalities and problems. We then performed EDA on the dataset to discover meaningful correlations between features. Then we engineered features via several methods including, creating dummies, mapping ordinal categories to numbers, creating new features based upon similar features, and creating polynomial features to determine reactions between features. All features were then scaled to prepare them for modeling and regularization.\n",
    "\n",
    "All of these engineered features were then tested on three linear regression models:\n",
    "- Ordinary Least Squares (OLS)\n",
    "- Ridge Regression (l2 penalty)\n",
    "- LASSO Regression (l1 penalty)\n",
    "\n",
    "From these models, it was determined that the Ridge and LASSO models performed best based on their $R^2$ and MSE scores. Both the Ridge and LASSO models utilized 10-fold cross-validation to improve their performance. The Ordinary Least Squares model outperformed the other two models on the training data, but worse on the test data. This is because the model was overfit. Because the Ridge and LASSO models utilize penalties, they can regularize the data to create more robust models that generalize better to new data.\n",
    "\n",
    "We have concluded that utilizing any of the three linear regression models with this data set can produce accurate predictions above the $R^2$ of 0.90 and < 30000 MSE threshold that Zillow provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b62403c",
   "metadata": {},
   "source": [
    "### Recommendations\n",
    "Based on our achievement of the success metrics and conclusions, we recommend that Zillow allocate more funding to further develop this home sale price prediction technology. Resources should be distributed to collect larger and better data sets as well as continue to refine and improve the current proof-of-concept models.\n",
    "\n",
    "We also recommend that if Zillow chooses to utilize models to predict the effect of certain aspects of a home on sale price rather than simply utilizing all information to predict the sale price, the complexity of the model be reduced by removing variables that exhibit multicollinearity. This would likely reduce the overall performance of the model, but would provide more clarity to how individual features affect sale price."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
